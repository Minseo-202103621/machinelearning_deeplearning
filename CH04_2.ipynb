{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVn3mdLMFDE+kTUejnzlfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minseo-202103621/machinelearning_deeplearning/blob/main/CH04_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 확률적 경사 하강법\n",
        "## 경사 하강법 알고리즘을 이해하고 대량의 데이터에서 분류 모델을 훈련하는 방법을 배운다.\n",
        "---\n",
        "## 점진적인 학습\n",
        "앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 훈련할 수 있게 된다면 훈련에 사용한 데이터를 모두 유지할 필요도 없고 앞서 학습한 생선을 까먹을 일도 없다. 이런 식의 훈련 방식을 ***점진적 학습*** 또는 온라인 학습이라고 부른다.\n",
        "\n",
        "대표적인 점진적 학습 알고리즘은 ***확률적 경사 하강법***이다.\n"
      ],
      "metadata": {
        "id": "TebW3aTI9xwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 확률적 경사 하강법\n",
        "경사 하강법은 경사를 따라 내려가는 방법을 의미한다.\n",
        "여기서는 가장 가파른 경사를 따라 빠르게 내려오는 것이 목표인 것이다. 하지만 안전하게 내려와야 한다. 즉 조금씩 내려오는 것도 중요하다는 소리이다.\n",
        "\n",
        "\n",
        "이제 확률적이라는 말을 생각해볼거다. 경사 하강법은 전체 샘플을 사용하여 훈련하지 않는다. 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라 가장 가파른 길을 찾는다. 이처럼 훈련 세트에서 랜덤하게 하나의 샘플을 고르는 것이 바로 ***확률적 경사 하강법***이다.\n",
        "\n",
        "\n",
        "자세히 설명하면 확률적 경사 하강법은 훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려간다. 그 다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려간다. 이런 식으로 전체 샘플을 모두 사용할 때까지 계속한다.\n",
        "\n",
        "만약 모든 샘플을 이용했는데도 산을 내려오지 못했다?? \n",
        "다시 처음부터 시작하면 된다. 훈련 세트에 모든 샘플을 다시 채워 넣고 다시 랜덤하게 하나의 샘플을 선택해 이어서 경사를 내려오면 된다. 이렇게 만족할만한 위치에 도달할 때까지 계속 내려가면 된다. 확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정을 ***에포크***라고 부른다. 일반적으로 경사 하강법은 수십,수백 번 이상 에포크를 수행한다.\n",
        "\n",
        "만약 1개씩 말고 무작위로 몇 개의 샘플을 선택해서 경사를 따라 내려가면...가능하다. 이런 방법을 ***미니배치 경사 하강법***이라고 한다.\n",
        "\n",
        "극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용할 수도 있다. 이를 ***배치 경사 하강법***이라고 부른다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3GOv9z9w_F8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 근데 어디서 내려가야 하는 거에요?? 이 산이 무슨 산인데여??"
      ],
      "metadata": {
        "id": "hXD8epk9Cs26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 손실함수\n",
        "\n",
        "손실함수는 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준이다. \n",
        "\n",
        "그렇기 때문에 손실 함수의 값이 작을수록 좋다. 하지만 어떤 값이 최솟값인지는 알지 못한다.\n",
        "\n",
        "가능한 많이 찾아보고 만족할만한 수준이라면 산을 다 내려왔다고 인정해야 한다. \n",
        "\n",
        "이 값을 찾아서 조금씩 이동하려면 확률적 경사 하강법이 잘 맞을거 같다.\n",
        "\n",
        "* 비용 함수(cost function)은 손실함수의 다른 말이다. 굳이 구분하자면 손실함수는 샘플 하나에 대한 손실을 정의하지만 비용함수는 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합이다. 하지만 보통 이 둘을 엄격히 구분 안하고 섞어서 사용한다.\n",
        "\n",
        "분류에서 손실은 아주 확실하다. 바로 정답을 못 맞추는 거다.\n",
        "그렇다면 정확도가 나올텐데 이 정확도를 손실 함수로 쓸 수 있지 않나?\n",
        "정확도 값에 음수를 취하면 값이 작을수록 정확도가 올라가는 뜻이니까 맞지 않나??\n",
        "\n",
        "응 안된다!\n",
        "\n",
        "정확도는 일단 듬성듬성이다. 만약 4개의 샘플이라면 정확도는 0,0.25,0.5,0.75,1뿐인데 너무 듬성듬성하다 이러면 조금씩 내려올 수가 없다. 산의 경사면은 연속적이어야 한다. 즉 기술적으로 손실 함수는 ***미분 가능***해야 한다."
      ],
      "metadata": {
        "id": "oLG1PJoRC95Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- \n",
        "## 로지스틱 손실 함수\n",
        "\n",
        "샘플 4개의 예측 확률을 각각 0.9,0.3,0.2,0.8이라고 가정해 보겠다.첫 번째와 두 번째는 타깃이 1이고 나머지 둘은 0이다.\n",
        "\n",
        "첫 번쨰 샘플의 예측은 0.9이므로 양성 클래스의 타깃인 1과 곱한 다음 음수로 바꿀 수 있다. 이 경우 예측이 1과 가까울수록 좋은 모델이다. 예측이 1에 가까울수록 예측과 타깃의 곱의 음수는 점점 작아진다. 이 값을 손실 함수로 사용해도 괜찮겠다.\n",
        "\n",
        "두 번째 샘플의 예측은 0.3이다. 타깃이 양성 클래스(1)인데 거리가 멀다. 위에서와 마찬가지로 예측과 타깃을 곱해 음수로 바꿔 보자. 이 값은 -0.3이기 떄문에 첫 번째 샘플보다 높은 손실이 된다.\n",
        "\n",
        "세 번째 샘플을 보자. 이 샘플의 타깃은 음성 클래스라 0이다. 이 값을 예측 확률이 0.2와 그대로 곱하면 무조건 0이다. 한 가지 방법은 타깃을 마치 양성 클래스처럼 바꾸어 1로 만드는 거다. 대신 예측값도 양성 클래스에 대한 예측으로 바꾼다. 즉 1-0.2 = 0.8을 사용한다. \n",
        "\n",
        "네 번쨰 샘플의 손실이 높다.\n",
        "\n",
        "예측 확률을 사용해 이런 방식으로 계산하면 연속적인 손실 함수를 얻을 수 있다. 여기에서 예측 확률에 로그 함수를 적용하면 더 좋다. 예측 확률의 범위는 0~1 사이인데 로그 함수는 이 사이에서 음수가 되므로 최종 손실 값은 양수가 된다. 손실이 양수가 되면 이해하기 더 쉽다. 또 로그 함수는 0에 가까울수록 아주 큰 음수가 되기 때문에 손실을 아주 크게 만들어 모델에 큰 영향을 미칠 수 있다.\n",
        "\n",
        "\n",
        "### 이렇게 멋지게 정의한 손실 함수를 ***로지스틱 손실 함수***라고 부른다. 또는 ***이진 크로스엔트로피 손실 함수***라고 부른다.\n",
        "\n",
        "* 이진 분류는 로지스틱 손실 함수를 사용하고 다중 분류는 크로스엔트로피 손실 함수를 사용한다.\n",
        "\n",
        "* 회귀에서는 손실함수로 평균 절대값 오차를 사용할 수 있다. 또는 평균 제곱 오차를 많이 사용한다."
      ],
      "metadata": {
        "id": "Ct_cjxo8GgX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## SGDClassifier"
      ],
      "metadata": {
        "id": "E5kRpdgnNouU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sx4HGdd9u8N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "metadata": {
        "id": "xTB_ayuxOCv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input,test_input,train_target,test_target = train_test_split(fish_input,fish_target,random_state=42)\n"
      ],
      "metadata": {
        "id": "m1KdPzBxOYJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)\n"
      ],
      "metadata": {
        "id": "pxzt4fxrO-_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 사이킷런에서 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스는 SGDClassifier이다. sklearn.linear_model 패키지 아래에서 임포트해 보겠다."
      ],
      "metadata": {
        "id": "wgRr7nSIPZXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "iBZTrTB8PUts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SGDClassifier의 객체를 만들 때 2개의 매개변수를 지정한다. loss는 손실 함수의 종류를 지정한다. 여기에서는 loss='log'로 지정하여 로지스틱 손실 함수를 지정한다. max_iter는 수행할 에포크 횟수를 지정한다. 10으로 지정하여 전체 훈련 세트를 10회 반복한다. 그다음 훈련 세트와 테스트 세트에서 정확도 점수를 출력한다.\n",
        "\n",
        "* 다중 분류일 경우 SGDClassifier에 loss='log'로 지정하면 클래스마다 이진 분류 모델을 만든다. 즉 도미는 양성 클래스로 두고 나머지를 모두 음성 클래스로 둔다. 이런 방식을 OvR이라고 부른다."
      ],
      "metadata": {
        "id": "yWYAXGhCPs70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SGDClassifier(loss='log',max_iter = 10,random_state=42)\n",
        "sc.fit(train_scaled,train_target)\n",
        "print(sc.score(train_scaled,train_target))\n",
        "print(sc.score(test_scaled,test_target))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DLAsV9JPogP",
        "outputId": "9fcc45e6-c377-4711-8dc4-20fe9a03839b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 앞서 말한 것처럼 확률적 경사 하강법은 점진적 학습이 가능하다. SGDClassifier 객체를 다시 만들지 않고 훈련한 모델 sc를 추가로 더 훈련해 보자. \n",
        "* 모델을 이어서 훈련할 때는 partial_fit()메서드를 사용한다.\n",
        "* 이 메서드는 fit() 메서드와 사용법이 같지만 호출할 때마다 1에포크씩 이어서 훈련할 수 있다.partial_fit() 메서드를 호출하고 다시 훈련 세트와 테스트 세트의 점수를 확인해 보자."
      ],
      "metadata": {
        "id": "hqHACh47Q1Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.partial_fit(train_scaled,train_target)\n",
        "print(sc.score(train_scaled,train_target))\n",
        "print(sc.score(test_scaled,test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe2gRT9eQtvV",
        "outputId": "ce57d493-d1af-4482-d45a-af3fc686091f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8151260504201681\n",
            "0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 여전히 점수가 낮지만 에포크를 한 번 더 실행하니 정확도가 향상됐다. 그런데 그럼 얼마나 더 훈련해야 해요??????????"
      ],
      "metadata": {
        "id": "7RHjy-sER72F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 에포크와 과대/과소적합\n",
        "\n",
        "에포크 횟수가 적으면 ? 모델이 훈련 세트를 덜 학습한다. 즉 산을 다 내려오지 못 하고 훈련을 마치는 셈이다. 에포크 횟수가 충분히 많으면 ? 훈련 세트를 완전히 학습한 것이다. 훈련세트에 아주 잘 맞는 모델이 만들어진거다.\n",
        "\n",
        "적은 에포크 횟수 동안에 훈련한 모델은 훈련 세트와 테스트 세트에 잘 맞지 않는 과소적합된 모델일 가능성이 높다. 반대로 많은 에포크 횟수 동안에 훈련한 모델은 훈련 세트에 너무 잘 맞아 테스트 세트에는 오히려 점수가 나쁜 과대적합된 모델일 가능성이 높다.\n",
        "\n",
        "과대적합이 시작하기 전에 훈련을 멈추는 것을 조기 종료라고 한다. 이 부분은 그래프를 그려 확인할 수 있고 그 그래프를 그려 보겠다.\n",
        "\n",
        "* 이 예제에서는 fit()메서드를 사용하지 않고 partial_fit() 메서드만 사용하겠다.\n",
        "* partial_fit()메서드만 사용하려면 하려면 훈련 세트에 있는 전체 클래스의 레이블을 partial_fit() 메서드에 전달해 주어야 한다. \n",
        "* 이를 위해 np.unique() 함수로 train_target에 있는 7개의 생선의 목록을 만든다. 또 에포크마다 훈련 세트와 테스트 세트에 대한 점수를 기록하기 위해 2개의 리스트를 준비한다.\n"
      ],
      "metadata": {
        "id": "ARxlFD1sSEfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "sc = SGDClassifier(loss='log',random_state=42)\n",
        "train_score = []\n",
        "test_score = []\n",
        "classes = np.unique(train_target)"
      ],
      "metadata": {
        "id": "_-uGynXvR5Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 300번의 에포크 동안 훈련을 반복하여 진행해 보겠다. 반복마다 훈련 세트와 테스트 세트의 점수를 계산하여 train_score,test_score 리스트에 추가한다."
      ],
      "metadata": {
        "id": "uKQsMvpCU_H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(0,300):\n",
        "  sc.partial_fit(train_scaled,train_target,classes = classes)\n",
        "  train_score.append(sc.score(train_scaled,train_target))\n",
        "  test_score.append(sc.score(test_scaled,test_target))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB1fBufrU2Y_",
        "outputId": "52c9b96a-d87a-402f-fb2c-ae0c1bbd1468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 300번의 에포크 동안 기록한 훈련 세트와 테스트 세트의 점수를 그래프로 그려 보겠다."
      ],
      "metadata": {
        "id": "96M4-OQdV3oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_score)\n",
        "plt.plot(test_score)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EXMgOrv9V2nZ",
        "outputId": "995036d1-d1d4-457b-cf87-76d2ad310693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터가 작기 때문에 아주 잘 드러나지는 않지만, 백 번째 에포크 이후에는 훈련 세트와 테스트 세트의 점수가 조금씩 벌어지고 있다. 또 확실히 에포크 초기에는 과소적합되어 훈련 세트와 테스트 세트의 점수가 낮다. 이 모델은 백 번째 에포크가 적절한 반복 횟수같다.\n",
        "* SGDClassifier의 반복 횟수를 100에 맞추고 모델을 다시 훈련해 보겠다. "
      ],
      "metadata": {
        "id": "xKB4t7uHWbU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SGDClassifier(loss='log',max_iter = 100,tol=None,random_state=42)\n",
        "sc.fit(train_scaled,train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "oUYAFKzrWOX2",
        "outputId": "92874a54-ce0f-45bf-e154-33b3b2019eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log', max_iter=100, random_state=42, tol=None)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(loss=&#x27;log&#x27;, max_iter=100, random_state=42, tol=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log&#x27;, max_iter=100, random_state=42, tol=None)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc.score(train_scaled,train_target))\n",
        "print(sc.score(test_scaled,test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRUkkPlJXLCH",
        "outputId": "fb888849-5b61-4182-9408-56e9a4b223f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.957983193277311\n",
            "0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동을 멈춘다. \n",
        "* tol 매개변수에서 향상될 최솟값을 지정한다. 앞의 코드에서는 tol 매개변수를 None으로 지정하여 자동으로 멈추지 않고 max_iter=100 만큼 무조건 반복하도록 했다."
      ],
      "metadata": {
        "id": "UAHGb6PBXsXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        " + loss 매개변수의 기본값은 'hinge이다. ***힌지 손실***은 ***서포트 벡터 머신***이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수이다.\n",
        " + 이처럼 SGDClassifier가 여러 종류의 손실 함수를 loss 매개변수에 지정하여 다양한 머신러닝 알고리즘을 지원한다는 것만 기억하면 된다."
      ],
      "metadata": {
        "id": "5k9QHB9qYRv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "30NH_eWaYQsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SGDClassifier(loss='hinge',max_iter = 100,tol=None,random_state=42)\n",
        "sc.fit(train_scaled,train_target)\n",
        "print(sc.score(train_scaled,train_target))\n",
        "print(sc.score(test_scaled,test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meoqm2NwXSJT",
        "outputId": "e5316bab-7c10-4c56-877f-50ef3f6b1ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9495798319327731\n",
            "0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6Hl6orNZGFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}